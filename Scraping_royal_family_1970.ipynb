{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\u0140177\\anaconda3\\lib\\site-packages (4.9.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\u0140177\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get('https://www.royal.uk/speeches')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a BeautifulSoup object\n",
    "soup_main = BeautifulSoup(page.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('All Members of the Royal Family', '')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the list of members of the royal house\n",
    "list_of_members=[]\n",
    "list_complete=soup_main.find(class_=\"form-item form-type-select form-item-mrf\").find_all('option')\n",
    "for i in list_complete:\n",
    "    list_of_members.append((i.text, i['value']))\n",
    "list_of_members.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I create a list with all the links to the speeches appearing when searching for each family member on the official Royal Family Website\n",
    "for i in list_of_members:\n",
    "    name=re.sub(' ', '', i[0])\n",
    "    if not os.path.exists('speeches/'+name):\n",
    "        os.makedirs('speeches/'+name)\n",
    "    page=requests.get('https://www.royal.uk/speeches?text=&mrf='+i[1]+'&date[min][date]=1%2F01%2F1970&date[max][date]=13%2F06%2F2022&id=')\n",
    "    soup=BeautifulSoup(page.text, 'html.parser')\n",
    "    if soup.find(class_=\"pager-last last\") is not None:\n",
    "        nb_last_page=soup.find(class_=\"pager-last last\").find('a').get('href').split('page=')[1]\n",
    "    else:\n",
    "        nb_last_page=0\n",
    "    #working with the first page\n",
    "    list_of_links_with_date=[]\n",
    "    link_infos= soup.find_all(class_='tbm-fields-container views-fieldset')\n",
    "    for item in link_infos:\n",
    "        link_ref=item.find('a')\n",
    "        link = 'https://www.royal.uk' + link_ref.get('href')\n",
    "        date=item.find(class_=\"date-display-single\")\n",
    "        year=date.text.split()[-1]\n",
    "        list_of_links_with_date.append((link, year))\n",
    "    #if there is more than one page, I work with the other pages\n",
    "    if nb_last_page!=0:\n",
    "        list_of_pages=[]\n",
    "        for j in range(1, int(nb_last_page)+1):\n",
    "            list_of_pages.append('https://www.royal.uk/speeches?text=&mrf='+i[1]+'&date[min][date]=01/01/1970&date[max][date]=13/06/2022&id=&page='+str(j)) \n",
    "        for m in list_of_pages:\n",
    "            page = requests.get(m)\n",
    "            soup = BeautifulSoup(page.text, 'html.parser')\n",
    "            link_infos= soup.find_all(class_='tbm-fields-container views-fieldset')\n",
    "            for item in link_infos:\n",
    "                link_ref=item.find('a')\n",
    "                link = 'https://www.royal.uk' + link_ref.get('href')\n",
    "                date=item.find(class_=\"date-display-single\")\n",
    "                year=date.text.split()[-1]\n",
    "                list_of_links_with_date.append((link, year))\n",
    "    #I print the list of links of the articles+year for every member of the Royal family\n",
    "    file = open('speeches/'+name+'/'+name+'links_and_dates.csv', 'w')\n",
    "    f=csv.writer(file)\n",
    "    for l in range(len(list_of_links_with_date)):\n",
    "        f.writerow([list_of_links_with_date[l][0], list_of_links_with_date[l][1]])\n",
    "    file.close()          \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.royal.uk/speech-following-death-diana-princess-wales\n",
      "https://www.royal.uk/speech-following-death-diana-princess-wales\n",
      "https://www.royal.uk/speech-following-death-diana-princess-wales\n",
      "https://www.royal.uk/speech-following-death-diana-princess-wales\n"
     ]
    }
   ],
   "source": [
    "#I retrieve all the speeches following the available links and print the links that appear to be broken\n",
    "for i in list_of_members:\n",
    "    name=re.sub(' ', '', i[0])\n",
    "    file_links='speeches/'+name+'/'+name+'links_and_dates.csv'\n",
    "    if os.stat(file_links).st_size != 0:\n",
    "        df=pd.read_csv(file_links, names=[\"link\", \"year\"])\n",
    "        for index, row in df.iterrows():\n",
    "            title='x'\n",
    "            content='x'\n",
    "            page = requests.get(row[\"link\"], allow_redirects=False) #This is necessary because of the fact that some links are broken\n",
    "            if page.status_code == 200:\n",
    "                soup = BeautifulSoup(page.text, 'html.parser')\n",
    "                last_links = soup.find(class_=\"tbm-share-links share\")\n",
    "                last_links.decompose()\n",
    "                if soup.find(class_=\"container article\").find('h1') is not None:\n",
    "                    title=re.sub('[^0-9a-zA-Z]+', '', soup.find(class_=\"container article\").find('h1').text)\n",
    "                if soup.find(class_=\"block block-system\").find(class_=\"content\") is not None:\n",
    "                    if soup.find(class_=\"block block-system\").find(class_=\"content\").find('blockquote') is not None:\n",
    "                        content_block= soup.find(class_=\"block block-system\").find(class_=\"content\")\n",
    "                        content_block.find('blockquote').decompose()\n",
    "                        content=content_block.find_all('p')\n",
    "                    else:\n",
    "                        content= soup.find(class_=\"block block-system\").find(class_=\"content\").find_all('p')\n",
    "                    content_text=''\n",
    "                    for j in content[:-1]:\n",
    "                        content_text+=j.text\n",
    "                f=open('speeches/'+name+'/'+name+'_'+str(row[\"year\"])+'_'+title+'.txt', 'w', encoding=\"utf-8\")\n",
    "                f.write(content_text)\n",
    "                f.close()\n",
    "            else:\n",
    "                print(row[\"link\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I manually add the speech for the death of Diana (broken link)\n",
    "page = requests.get(\"https://www.royal.uk/queens-message-following-death-diana-princess-wales\")\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "last_links = soup.find(class_=\"tbm-share-links share\")\n",
    "last_links.decompose()\n",
    "if soup.find(class_=\"container article\").find('h1') is not None:\n",
    "    title=re.sub('[^0-9a-zA-Z]+', '', soup.find(class_=\"container article\").find('h1').text)\n",
    "if soup.find(class_=\"block block-system\").find(class_=\"content\") is not None:\n",
    "    if soup.find(class_=\"block block-system\").find(class_=\"content\").find('blockquote') is not None:\n",
    "        content_block= soup.find(class_=\"block block-system\").find(class_=\"content\")\n",
    "        content_block.find('blockquote').decompose()\n",
    "        content=content_block.find_all('p')\n",
    "    else:\n",
    "        content= soup.find(class_=\"block block-system\").find(class_=\"content\").find_all('p')\n",
    "    content_text=''\n",
    "    for j in content[:-1]:\n",
    "        content_text+=j.text\n",
    "f=open('speeches/HerMajestyTheQueen/HerMajestyTheQueen_1997_'+title+'.txt', 'w', encoding=\"utf-8\")\n",
    "f.write(content_text)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1953\n",
      "1954\n",
      "1955\n",
      "1956\n",
      "1957\n",
      "1958\n",
      "1959\n",
      "1960\n",
      "1961\n",
      "1962\n",
      "1963\n",
      "1964\n",
      "1965\n",
      "1966\n",
      "1967\n",
      "1968\n",
      "1969\n"
     ]
    }
   ],
   "source": [
    "#I manually add the Christmas Broadcasts before 1970 (not appearing in the search)\n",
    "page = requests.get(\"https://www.royal.uk/queens-first-christmas-broadcast-1952\")\n",
    "soup = BeautifulSoup(page.text, 'html.parser')\n",
    "last_links = soup.find(class_=\"tbm-share-links share\")\n",
    "last_links.decompose()\n",
    "if soup.find(class_=\"container article\").find('h1') is not None:\n",
    "    title=re.sub('[^0-9a-zA-Z]+', '', soup.find(class_=\"container article\").find('h1').text)\n",
    "if soup.find(class_=\"block block-system\").find(class_=\"content\") is not None:\n",
    "    if soup.find(class_=\"block block-system\").find(class_=\"content\").find('blockquote') is not None:\n",
    "        content_block= soup.find(class_=\"block block-system\").find(class_=\"content\")\n",
    "        content_block.find('blockquote').decompose()\n",
    "        content=content_block.find_all('p')\n",
    "    else:\n",
    "        content= soup.find(class_=\"block block-system\").find(class_=\"content\").find_all('p')\n",
    "    content_text=''\n",
    "    for j in content[:-1]:\n",
    "        content_text+=j.text\n",
    "f=open('speeches/HerMajestyTheQueen/HerMajestyTheQueen_1952_'+title+'.txt', 'w', encoding=\"utf-8\")\n",
    "f.write(content_text)\n",
    "f.close()\n",
    "for i in range (1953, 1970):\n",
    "    page = requests.get(\"https://www.royal.uk/christmas-broadcast-\"+str(i))\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    last_links = soup.find(class_=\"tbm-share-links share\")\n",
    "    last_links.decompose()\n",
    "    if soup.find(class_=\"container article\").find('h1') is not None:\n",
    "        title=re.sub('[^0-9a-zA-Z]+', '', soup.find(class_=\"container article\").find('h1').text)\n",
    "    if soup.find(class_=\"block block-system\").find(class_=\"content\") is not None:\n",
    "        content= soup.find(class_=\"block block-system\").find(class_=\"content\").find_all('p')\n",
    "        content_text=''\n",
    "        for j in content[:-1]:\n",
    "            content_text+=j.text\n",
    "    f=open('speeches/HerMajestyTheQueen/HerMajestyTheQueen_'+str(i)+'_'+title+'.txt', 'w', encoding=\"utf-8\")\n",
    "    f.write(content_text)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
